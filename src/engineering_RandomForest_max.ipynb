{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #to supress import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLUMNS = ['station','date','feature', 'value', 'measurement','quality', 'source', 'hour']\n",
    "COLUMNS_test = ['station','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('../data/export_features_loc_MAX.csv', index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['date'] = pd.to_datetime(df_train['date'], format='%Y%m%d', errors='ignore')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you want to use past days as predictor?\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get year and date as features\n",
    "df = df_train\n",
    "df = df_train_yd.drop(columns='date')\n",
    "df['year'] = df_train['date'].map(lambda x: x.year)\n",
    "df['day'] = df_train['date'].map(lambda x: x.timetuple().tm_yday)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data to reduce preproccesing duration\n",
    "#df_train_yd.to_csv('../data/tmp/export_LSMT_MAX_yd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data ready for LMST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the preprocessed data for a quicker start\n",
    "df = pd.read_csv('../data/tmp/export_LSMT_MAX_yd.csv', index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>elev</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>AG000060590</td>\n",
       "      <td>30</td>\n",
       "      <td>30.5667</td>\n",
       "      <td>2.8667</td>\n",
       "      <td>397.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>AG000060590</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5667</td>\n",
       "      <td>2.8667</td>\n",
       "      <td>397.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>AG000060590</td>\n",
       "      <td>36</td>\n",
       "      <td>30.5667</td>\n",
       "      <td>2.8667</td>\n",
       "      <td>397.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>AG000060590</td>\n",
       "      <td>60</td>\n",
       "      <td>30.5667</td>\n",
       "      <td>2.8667</td>\n",
       "      <td>397.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>AG000060590</td>\n",
       "      <td>50</td>\n",
       "      <td>30.5667</td>\n",
       "      <td>2.8667</td>\n",
       "      <td>397.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          station  TMIN      lat    long   elev  year  day\n",
       "4039  AG000060590    30  30.5667  2.8667  397.0  2014    1\n",
       "4040  AG000060590    31  30.5667  2.8667  397.0  2014    2\n",
       "4041  AG000060590    36  30.5667  2.8667  397.0  2014    3\n",
       "4042  AG000060590    60  30.5667  2.8667  397.0  2014    4\n",
       "4043  AG000060590    50  30.5667  2.8667  397.0  2014    5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick random stations for test and training\n",
    "seed = 93598357\n",
    "np.random.seed(seed)\n",
    "stations = df.station.unique()\n",
    "np.random.shuffle(stations)\n",
    "stations_shuffled = stations\n",
    "stations_train = stations_shuffled[:2000]\n",
    "stations_holdout = stations_shuffled[2000:4000]\n",
    "\n",
    "df_train_test = df[df['station'].isin(stations_train)]\n",
    "df_train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1792641, 7) (514252, 7)\n"
     ]
    }
   ],
   "source": [
    "#divide test and training to test effective of model to different timeframe (start of 2017)\n",
    "training_years = [2014,2015,2016]\n",
    "testing_days = range(80)\n",
    "\n",
    "df_train = df_train_test[df_train_test['year'].isin(training_years)]\n",
    "df_test = df_train_test[df_train_test['day'].isin(testing_days)]\n",
    "print(df_train.shape,df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate target from features\n",
    "df_X_train_raw = df_train.drop(columns='TMIN')\n",
    "df_X_test_raw = df_test.drop(columns='TMIN')\n",
    "sy_train = df_train['TMIN']\n",
    "sy_test = df_test['TMIN']\n",
    "y_train_raw = sy_train.reshape(-1,1)\n",
    "y_test_raw = sy_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1792641, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int encode stations\n",
    "#LB = LabelBinarizer()\n",
    "#df_X['station'] = LB.fit_transform(df_X[['station']])\n",
    "df_X_train_red = df_X_train_raw.drop(columns='station')\n",
    "df_X_test_red = df_X_test_raw.drop(columns='station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_dict = df_X.to_dict('records')\n",
    "#vec = DictVectorizer()\n",
    "#X = vec.fit_transform(X_dict).toarray()\n",
    "#X_dummies = pd.get_dummies(df_X)\n",
    "#X = X_dummies.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "X_train_raw = df_X_train_red.values\n",
    "X_test_raw = df_X_test_red.values\n",
    "X_train_raw = X_train_raw.astype('float32')\n",
    "X_test_raw = X_test_raw.astype('float32')\n",
    "y_train_raw = y_train_raw.astype('float32')\n",
    "y_test_raw = y_test_raw.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))                             \n",
    "train_X = scaler.fit_transform(X_train_raw)\n",
    "test_X = scaler.fit_transform(X_test_raw)\n",
    "train_y = scaler.fit_transform(y_train_raw).ravel()\n",
    "test_y = scaler.fit_transform(y_test_raw).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1792641, 5) (1792641,) (514252, 5) (514252,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape,train_y.shape,test_X.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1626275646978168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514252, 1) (514252, 5)\n"
     ]
    }
   ],
   "source": [
    "yhat = regr.predict(test_X)\n",
    "\n",
    "print(yhat.reshape(514252,1).shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 135.783\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = regr.predict(test_X)\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat.reshape(514252,1), test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200, total= 2.9min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200, total= 3.0min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200, total= 3.0min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200, total= 2.9min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=500, total= 7.6min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200, total= 3.6min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=500, total= 8.3min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=500, total= 8.3min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200, total= 3.7min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=200, total= 3.6min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=200, total= 2.7min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=500, total= 8.2min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=500, total= 7.6min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=500, total= 7.6min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=200, total= 3.0min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=200, total= 3.8min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=500, total= 9.3min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=500, total= 9.5min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=2, n_estimators=500, total= 9.5min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=200, total= 4.2min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=200, total= 3.8min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200, total= 5.8min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=500, total= 9.3min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=500, total= 9.3min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=3, min_samples_leaf=5, min_samples_split=5, n_estimators=500, total= 9.5min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200, total= 5.7min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200, total= 5.5min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200, total= 6.0min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500, total=14.4min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500, total=15.0min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200, total= 5.5min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500, total=13.6min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200, total= 4.7min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 59.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=200, total= 6.0min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500, total=14.2min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500, total=14.3min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=200, total= 6.2min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500, total=14.8min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=200, total= 6.1min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200, total= 6.4min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=500, total=14.9min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=500, total=15.5min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200, total= 5.8min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=2, n_estimators=500, total=14.7min\n",
      "[CV] bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200, total= 5.1min\n",
      "[CV] bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=500, total=11.7min\n",
      "[CV] bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=500, total=12.5min\n",
      "[CV] bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, max_features=5, min_samples_leaf=5, min_samples_split=5, n_estimators=500, total=11.9min\n",
      "[CV] bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200, total=22.6min\n",
      "[CV] bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200, total=25.3min\n",
      "[CV]  bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200, total=25.0min\n",
      "[CV] bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV] bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200, total=20.0min\n",
      "[CV] bootstrap=True, max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [200, 500],\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": [3, 5],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 5],\n",
    "    \"bootstrap\": [True, False]}\n",
    "\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "grid = GridSearchCV(estimator=model, verbose=2, param_grid=param_grid, n_jobs=-1)\n",
    "grid.fit(train_X, train_y)\n",
    " \n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [200, 500],\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": [3, 5],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 5],\n",
    "    \"bootstrap\": [True, False]}\n",
    "\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "grid = GridSearchCV(estimator=model, verbose=2, param_grid=param_grid, n_jobs=-1)\n",
    "grid.fit(train_X, train_y)\n",
    " \n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [200, 500, 1000],\n",
    "    \"max_depth\": [1, 2, 3, 5, None],\n",
    "    \"max_features\": [1, 3, 5],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 3, 10],\n",
    "    \"bootstrap\": [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat.reshape(514252,1), test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = '../data/export_features_2014_to_2017_20.csv'\n",
    "STATIONS_FILE = '../data/ghcnd-stations.csv'\n",
    "\n",
    "def get_original_df():\n",
    "    df_original = pd.read_csv(TRAIN_FILE)\n",
    "    df_original = df_original.drop(['Unnamed: 0'], axis=1)\n",
    "    return df_original\n",
    "\n",
    "def get_station_df():\n",
    "     return pd.read_csv(STATIONS_FILE, header=None, names=['station','lat', 'long', 'elev'], sep=';')\n",
    "\n",
    "def add_coordinates(df_src, df_stations, src_index='station', foreign_index='station'):\n",
    "    df_out = df_src.copy()\n",
    "    return df_out.join(df_stations.set_index(foreign_index), on=src_index)\n",
    "\n",
    "def add_day_of_year_column(df_src, column_name='date'):\n",
    "    df_out = df_src.copy()\n",
    "    df_out['day_of_year'] = df_out[column_name].apply(lambda d: date_to_nth_day(str(d)))\n",
    "    return df_out\n",
    "\n",
    "def date_to_nth_day(date, format='%Y%m%d'):\n",
    "    date = datetime.datetime.strptime(date, format)\n",
    "    new_year_day = datetime.datetime(year=date.year, month=1, day=1)\n",
    "    return (date - new_year_day).days + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set Up Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_original_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TMIN_1</th>\n",
       "      <th>TMIN_2</th>\n",
       "      <th>TMIN_3</th>\n",
       "      <th>TMIN_4</th>\n",
       "      <th>TMIN_5</th>\n",
       "      <th>TMIN_6</th>\n",
       "      <th>TMIN_7</th>\n",
       "      <th>...</th>\n",
       "      <th>TMIN_11</th>\n",
       "      <th>TMIN_12</th>\n",
       "      <th>TMIN_13</th>\n",
       "      <th>TMIN_14</th>\n",
       "      <th>TMIN_15</th>\n",
       "      <th>TMIN_16</th>\n",
       "      <th>TMIN_17</th>\n",
       "      <th>TMIN_18</th>\n",
       "      <th>TMIN_19</th>\n",
       "      <th>TMIN_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140101</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140102</td>\n",
       "      <td>145</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140103</td>\n",
       "      <td>140</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140106</td>\n",
       "      <td>162</td>\n",
       "      <td>140.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140109</td>\n",
       "      <td>115</td>\n",
       "      <td>162.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station      date  TMIN  TMIN_1  TMIN_2  TMIN_3  TMIN_4  TMIN_5  \\\n",
       "0  AE000041196  20140101   128     NaN     NaN     NaN     NaN     NaN   \n",
       "1  AE000041196  20140102   145   128.0     NaN     NaN     NaN     NaN   \n",
       "2  AE000041196  20140103   140   145.0   128.0     NaN     NaN     NaN   \n",
       "3  AE000041196  20140106   162   140.0   145.0   128.0     NaN     NaN   \n",
       "4  AE000041196  20140109   115   162.0   140.0   145.0   128.0     NaN   \n",
       "\n",
       "   TMIN_6  TMIN_7   ...     TMIN_11  TMIN_12  TMIN_13  TMIN_14  TMIN_15  \\\n",
       "0     NaN     NaN   ...         NaN      NaN      NaN      NaN      NaN   \n",
       "1     NaN     NaN   ...         NaN      NaN      NaN      NaN      NaN   \n",
       "2     NaN     NaN   ...         NaN      NaN      NaN      NaN      NaN   \n",
       "3     NaN     NaN   ...         NaN      NaN      NaN      NaN      NaN   \n",
       "4     NaN     NaN   ...         NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "   TMIN_16  TMIN_17  TMIN_18  TMIN_19  TMIN_20  \n",
       "0      NaN      NaN      NaN      NaN      NaN  \n",
       "1      NaN      NaN      NaN      NaN      NaN  \n",
       "2      NaN      NaN      NaN      NaN      NaN  \n",
       "3      NaN      NaN      NaN      NaN      NaN  \n",
       "4      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# df.groupby(['loc', 'date']).mean()\n",
    "# df.groupby('20150101').count()df_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = get_station_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>elev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>25.2550</td>\n",
       "      <td>55.3640</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td>24.4330</td>\n",
       "      <td>54.6510</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station      lat     long  elev\n",
       "0  ACW00011604  17.1167 -61.7833  10.1\n",
       "1  ACW00011647  17.1333 -61.7833  19.2\n",
       "2  AE000041196  25.3330  55.5170  34.0\n",
       "3  AEM00041194  25.2550  55.3640  10.4\n",
       "4  AEM00041217  24.4330  54.6510  26.8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TMIN_1</th>\n",
       "      <th>TMIN_2</th>\n",
       "      <th>TMIN_3</th>\n",
       "      <th>TMIN_4</th>\n",
       "      <th>TMIN_5</th>\n",
       "      <th>TMIN_6</th>\n",
       "      <th>TMIN_7</th>\n",
       "      <th>...</th>\n",
       "      <th>TMIN_14</th>\n",
       "      <th>TMIN_15</th>\n",
       "      <th>TMIN_16</th>\n",
       "      <th>TMIN_17</th>\n",
       "      <th>TMIN_18</th>\n",
       "      <th>TMIN_19</th>\n",
       "      <th>TMIN_20</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>elev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140101</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140102</td>\n",
       "      <td>145</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140103</td>\n",
       "      <td>140</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140106</td>\n",
       "      <td>162</td>\n",
       "      <td>140.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140109</td>\n",
       "      <td>115</td>\n",
       "      <td>162.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station      date  TMIN  TMIN_1  TMIN_2  TMIN_3  TMIN_4  TMIN_5  \\\n",
       "0  AE000041196  20140101   128     NaN     NaN     NaN     NaN     NaN   \n",
       "1  AE000041196  20140102   145   128.0     NaN     NaN     NaN     NaN   \n",
       "2  AE000041196  20140103   140   145.0   128.0     NaN     NaN     NaN   \n",
       "3  AE000041196  20140106   162   140.0   145.0   128.0     NaN     NaN   \n",
       "4  AE000041196  20140109   115   162.0   140.0   145.0   128.0     NaN   \n",
       "\n",
       "   TMIN_6  TMIN_7  ...   TMIN_14  TMIN_15  TMIN_16  TMIN_17  TMIN_18  TMIN_19  \\\n",
       "0     NaN     NaN  ...       NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1     NaN     NaN  ...       NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2     NaN     NaN  ...       NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3     NaN     NaN  ...       NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "4     NaN     NaN  ...       NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "   TMIN_20     lat    long  elev  \n",
       "0      NaN  25.333  55.517  34.0  \n",
       "1      NaN  25.333  55.517  34.0  \n",
       "2      NaN  25.333  55.517  34.0  \n",
       "3      NaN  25.333  55.517  34.0  \n",
       "4      NaN  25.333  55.517  34.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined = add_coordinates(df, df_stations)\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TMIN_1</th>\n",
       "      <th>TMIN_2</th>\n",
       "      <th>TMIN_3</th>\n",
       "      <th>TMIN_4</th>\n",
       "      <th>TMIN_5</th>\n",
       "      <th>TMIN_6</th>\n",
       "      <th>TMIN_7</th>\n",
       "      <th>...</th>\n",
       "      <th>TMIN_15</th>\n",
       "      <th>TMIN_16</th>\n",
       "      <th>TMIN_17</th>\n",
       "      <th>TMIN_18</th>\n",
       "      <th>TMIN_19</th>\n",
       "      <th>TMIN_20</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>elev</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140101</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140102</td>\n",
       "      <td>145</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140103</td>\n",
       "      <td>140</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140106</td>\n",
       "      <td>162</td>\n",
       "      <td>140.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140109</td>\n",
       "      <td>115</td>\n",
       "      <td>162.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station      date  TMIN  TMIN_1  TMIN_2  TMIN_3  TMIN_4  TMIN_5  \\\n",
       "0  AE000041196  20140101   128     NaN     NaN     NaN     NaN     NaN   \n",
       "1  AE000041196  20140102   145   128.0     NaN     NaN     NaN     NaN   \n",
       "2  AE000041196  20140103   140   145.0   128.0     NaN     NaN     NaN   \n",
       "3  AE000041196  20140106   162   140.0   145.0   128.0     NaN     NaN   \n",
       "4  AE000041196  20140109   115   162.0   140.0   145.0   128.0     NaN   \n",
       "\n",
       "   TMIN_6  TMIN_7     ...       TMIN_15  TMIN_16  TMIN_17  TMIN_18  TMIN_19  \\\n",
       "0     NaN     NaN     ...           NaN      NaN      NaN      NaN      NaN   \n",
       "1     NaN     NaN     ...           NaN      NaN      NaN      NaN      NaN   \n",
       "2     NaN     NaN     ...           NaN      NaN      NaN      NaN      NaN   \n",
       "3     NaN     NaN     ...           NaN      NaN      NaN      NaN      NaN   \n",
       "4     NaN     NaN     ...           NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "   TMIN_20     lat    long  elev  day_of_year  \n",
       "0      NaN  25.333  55.517  34.0            1  \n",
       "1      NaN  25.333  55.517  34.0            2  \n",
       "2      NaN  25.333  55.517  34.0            3  \n",
       "3      NaN  25.333  55.517  34.0            6  \n",
       "4      NaN  25.333  55.517  34.0            9  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date = add_day_of_year_column(df_joined)\n",
    "df_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.to_csv('../data/df_train_mike.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, PATH):\n",
    "    joblib.dump(model, PATH) \n",
    "    \n",
    "def load_model(PATH):\n",
    "    return joblib.load(PATH) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TMIN_1</th>\n",
       "      <th>TMIN_2</th>\n",
       "      <th>TMIN_3</th>\n",
       "      <th>TMIN_4</th>\n",
       "      <th>TMIN_5</th>\n",
       "      <th>TMIN_6</th>\n",
       "      <th>TMIN_7</th>\n",
       "      <th>...</th>\n",
       "      <th>TMIN_15</th>\n",
       "      <th>TMIN_16</th>\n",
       "      <th>TMIN_17</th>\n",
       "      <th>TMIN_18</th>\n",
       "      <th>TMIN_19</th>\n",
       "      <th>TMIN_20</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>elev</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140202</td>\n",
       "      <td>155</td>\n",
       "      <td>147.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>159.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140203</td>\n",
       "      <td>155</td>\n",
       "      <td>155.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140207</td>\n",
       "      <td>99</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140208</td>\n",
       "      <td>112</td>\n",
       "      <td>99.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20140209</td>\n",
       "      <td>123</td>\n",
       "      <td>112.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station      date  TMIN  TMIN_1  TMIN_2  TMIN_3  TMIN_4  TMIN_5  \\\n",
       "20  AE000041196  20140202   155   147.0   149.0   130.0   138.0   123.0   \n",
       "21  AE000041196  20140203   155   155.0   147.0   149.0   130.0   138.0   \n",
       "22  AE000041196  20140207    99   155.0   155.0   147.0   149.0   130.0   \n",
       "23  AE000041196  20140208   112    99.0   155.0   155.0   147.0   149.0   \n",
       "24  AE000041196  20140209   123   112.0    99.0   155.0   155.0   147.0   \n",
       "\n",
       "    TMIN_6  TMIN_7     ...       TMIN_15  TMIN_16  TMIN_17  TMIN_18  TMIN_19  \\\n",
       "20   115.0   120.0     ...         159.0    115.0    162.0    140.0    145.0   \n",
       "21   123.0   115.0     ...         145.0    159.0    115.0    162.0    140.0   \n",
       "22   138.0   123.0     ...         137.0    145.0    159.0    115.0    162.0   \n",
       "23   130.0   138.0     ...         118.0    137.0    145.0    159.0    115.0   \n",
       "24   149.0   130.0     ...         117.0    118.0    137.0    145.0    159.0   \n",
       "\n",
       "    TMIN_20     lat    long  elev  day_of_year  \n",
       "20    128.0  25.333  55.517  34.0           33  \n",
       "21    145.0  25.333  55.517  34.0           34  \n",
       "22    140.0  25.333  55.517  34.0           38  \n",
       "23    162.0  25.333  55.517  34.0           39  \n",
       "24    115.0  25.333  55.517  34.0           40  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/df_train_mike.csv')\n",
    "df_train = df_train.drop(['Unnamed: 0'], axis=1)\n",
    "df_train = df_train.dropna(axis=0, how='any')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_random_forest_model():\n",
    "    TRAIN_COLUMNS = [\n",
    "        'day_of_year',\n",
    "        'lat',\n",
    "        'long',\n",
    "        'elev',\n",
    "    ]\n",
    "\n",
    "    y = df_train['TMIN']\n",
    "    X = df_train[TRAIN_COLUMNS]\n",
    "\n",
    "    regr = RandomForestRegressor(n_estimators=100, min_samples_split=10, min_samples_leaf=10, max_features=3, max_depth=3, bootstrap=True, random_state=1337)\n",
    "    regr.fit(X, y)\n",
    "\n",
    "    save_model(regr, '../models/mike/simple_random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_20_days_random_forest_model():\n",
    "    TRAIN_COLUMNS = [\n",
    "        'day_of_year',\n",
    "        'lat',\n",
    "        'long',\n",
    "        'elev',\n",
    "        'TMIN_1',\n",
    "        'TMIN_2',\n",
    "        'TMIN_3',\n",
    "        'TMIN_4',\n",
    "        'TMIN_5',\n",
    "        'TMIN_6',\n",
    "        'TMIN_7',\n",
    "        'TMIN_8',\n",
    "        'TMIN_9',\n",
    "        'TMIN_10',\n",
    "        'TMIN_11',\n",
    "        'TMIN_12',\n",
    "        'TMIN_13',\n",
    "        'TMIN_14',\n",
    "        'TMIN_15',\n",
    "        'TMIN_16',\n",
    "        'TMIN_17',\n",
    "        'TMIN_18',\n",
    "        'TMIN_19',\n",
    "        'TMIN_20',\n",
    "    ]\n",
    "\n",
    "    y = df_train['TMIN']\n",
    "    X = df_train[TRAIN_COLUMNS]\n",
    "\n",
    "    regr = RandomForestRegressor(n_estimators=100, min_samples_split=10, min_samples_leaf=10, bootstrap=True, random_state=1337)\n",
    "    regr.fit(X, y)\n",
    "\n",
    "    save_model(regr, '../models/mike/20_days_random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_5_days_random_forest_model():\n",
    "    TRAIN_COLUMNS = [\n",
    "        'day_of_year',\n",
    "        'lat',\n",
    "        'long',\n",
    "        'elev',\n",
    "        'TMIN_1',\n",
    "        'TMIN_2',\n",
    "        'TMIN_3',\n",
    "        'TMIN_4',\n",
    "        'TMIN_5',\n",
    "    ]\n",
    "\n",
    "    y = df_train['TMIN']\n",
    "    X = df_train[TRAIN_COLUMNS]\n",
    "\n",
    "    regr = RandomForestRegressor(n_estimators=100, min_samples_split=10, min_samples_leaf=10, bootstrap=True, random_state=1337)\n",
    "    regr.fit(X, y)\n",
    "\n",
    "    save_model(regr, '../models/mike/5_days_random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_simple_random_forest_model()\n",
    "train_20_days_random_forest_model()\n",
    "train_5_days_random_forest_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_PATH = '../data/2018_test.csv'\n",
    "def load_submission_file():\n",
    "    df_test = pd.read_csv(SUBMISSION_PATH)\n",
    "    return df_test\n",
    "\n",
    "def prepare_submission_file(df_test):\n",
    "    df_stations = get_station_df()\n",
    "    df_out = add_coordinates(df_test, df_stations, src_index='ID', foreign_index='station')\n",
    "    df_out = add_day_of_year_column(df_out, column_name='DATE')\n",
    "    return df_out\n",
    "    \n",
    "def save_submission(df_src, PATH):\n",
    "    df_submission = pd.DataFrame()\n",
    "    df_submission['SUB_ID'] = df_src['DATE'].apply(lambda d: str(d)) + df_src['ID']\n",
    "    df_submission['DATA_VALUE'] = df_src['DATA_VALUE']\n",
    "    df_submission.to_csv(PATH, index=False)\n",
    "    return df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_from_simple_random_forest_model():\n",
    "    model = load_model('../models/mike/simple_random_forest.pkl')\n",
    "    required_features = [\n",
    "        'day_of_year',\n",
    "        'lat',\n",
    "        'long',\n",
    "        'elev',\n",
    "        ]\n",
    "    PREDICITON_FILE_PATH = '../data/predictions/prediction_simple_random_forest.csv'\n",
    "\n",
    "    df_test = load_submission_file()\n",
    "    df_test = prepare_submission_file(df_test)\n",
    "    df_test.head()\n",
    "\n",
    "    # create predictions\n",
    "    df_predict = df_test\n",
    "    df_predict['DATA_VALUE'] = model.predict(df_test[required_features])\n",
    "\n",
    "    #save predictions\n",
    "    df_submission = save_submission(df_predict, PREDICITON_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for iteratively generating predictions\n",
    "\n",
    "def load_compltete_test_frame():\n",
    "     return pd.read_csv('../data/2018_submission_complete.csv')\n",
    "\n",
    "def generate_complete_test_frame(df_src):\n",
    "    df_test = pd.DataFrame(columns=['ID', 'DATE'])\n",
    "    stations = df_src['ID'].unique()\n",
    "    for i, station in enumerate(stations):\n",
    "        print('Station (',i,'/',len(stations),') ::', station, '\\r', end='')\n",
    "        required_dates = [\n",
    "            '20180101',\n",
    "            '20180102',\n",
    "            '20180103',\n",
    "            '20180104',\n",
    "            '20180105',\n",
    "            '20180106',\n",
    "            '20180107',\n",
    "            '20180108',\n",
    "            '20180109',\n",
    "            '20180110',\n",
    "            '20180111',\n",
    "            '20180112',\n",
    "            '20180113',\n",
    "            '20180114',\n",
    "            '20180115',\n",
    "            '20180116',\n",
    "            '20180117',\n",
    "            '20180118',\n",
    "            '20180119',\n",
    "            '20180120',\n",
    "            '20180121',\n",
    "            '20180122',\n",
    "            '20180123',\n",
    "            '20180124',\n",
    "            '20180125',\n",
    "            '20180126',\n",
    "            '20180127',\n",
    "            '20180128',\n",
    "            '20180129',\n",
    "            '20180130',\n",
    "            '20180131',\n",
    "            '20180201',\n",
    "            '20180202',\n",
    "            '20180203',\n",
    "            '20180204',\n",
    "            '20180205',\n",
    "            '20180206',\n",
    "            '20180207',\n",
    "            '20180208',\n",
    "            '20180209',\n",
    "            '20180210',\n",
    "            '20180211',\n",
    "            '20180212',\n",
    "            '20180213',\n",
    "            '20180214',\n",
    "            '20180215',\n",
    "            '20180216',\n",
    "            '20180217',\n",
    "            '20180218',\n",
    "            '20180219',\n",
    "            '20180220',\n",
    "        ]\n",
    "        \n",
    "        rows = []\n",
    "        for date in required_dates:\n",
    "            rows.append([station, str(date)])\n",
    "\n",
    "        df_append = pd.DataFrame(rows, columns=['ID', 'DATE'])\n",
    "        df_test = df_test.append(df_append)\n",
    "\n",
    "    print('')\n",
    "    return df_test\n",
    "\n",
    "def generate_and_save_complete_test_frame():\n",
    "    print('* Loading submission file')\n",
    "    df_test = load_submission_file()\n",
    "\n",
    "    # fill in the missing days\n",
    "    print('* Generating complete test frame \\t\\t\\t',)\n",
    "    df_test = generate_complete_test_frame(df_test)\n",
    "    \n",
    "    df_test.to_csv('../data/2018_submission_complete.csv', index=False)\n",
    "    \n",
    "def generate_initial_lookup_of_last_20_days():\n",
    "    COLUMNS = ['station','date','feature', 'value', 'measurement','quality', 'source', 'hour']\n",
    "    df_lookup = pd.read_csv('../data/df_train_mike.csv')\n",
    "    df_lookup = df_lookup[['station', 'date', 'TMIN']]\n",
    "    df_lookup = df_lookup[df_lookup['date'].isin([\n",
    "        '20171231',\n",
    "        '20171230',\n",
    "        '20171229',\n",
    "        '20171228',\n",
    "        '20171227',\n",
    "        '20171226',\n",
    "        '20171225',\n",
    "        '20171224',\n",
    "        '20171223',\n",
    "        '20171222',\n",
    "        '20171221',\n",
    "        '20171220',\n",
    "        '20171219',\n",
    "        '20171218',\n",
    "        '20171217',\n",
    "        '20171216',\n",
    "        '20171215',\n",
    "        '20171214',\n",
    "        '20171213',\n",
    "        '20171212',\n",
    "        '20171211',\n",
    "        '20171210',\n",
    "    ])]\n",
    "    df_lookup = add_day_of_year_column(df_lookup, column_name='date')\n",
    "    df_lookup = df_lookup.sort_values(by=['station', 'date'])\n",
    "    \n",
    "    return df_lookup\n",
    "\n",
    "def get_last_20_day_indeces(current_day_index):\n",
    "    return list(map(lambda i: (i-1) % 366, range(current_day_index-20, current_day_index)))\n",
    "\n",
    "def get_last_5_day_indeces(current_day_index):\n",
    "    return list(map(lambda i: (i-1) % 366, range(current_day_index-5, current_day_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_from_lookup(df_look_up, day_of_year):\n",
    "    df_sorted_and_filtered = df_look_up[df_look_up['day_of_year'] <= day_of_year].sort_values(by=['day_of_year'], ascending=False)\n",
    "    if len(df_sorted_and_filtered) == 0:\n",
    "        return 120\n",
    "    else:\n",
    "        return df_sorted_and_filtered.iloc[0]['TMIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_from_20_days_random_forest_model():\n",
    "    model = load_model('../models/mike/20_days_random_forest.pkl')\n",
    "    TRAIN_COLUMNS = [\n",
    "        'day_of_year',\n",
    "        'lat',\n",
    "        'long',\n",
    "        'elev',\n",
    "        'TMIN_1',\n",
    "        'TMIN_2',\n",
    "        'TMIN_3',\n",
    "        'TMIN_4',\n",
    "        'TMIN_5',\n",
    "        'TMIN_6',\n",
    "        'TMIN_7',\n",
    "        'TMIN_8',\n",
    "        'TMIN_9',\n",
    "        'TMIN_10',\n",
    "        'TMIN_11',\n",
    "        'TMIN_12',\n",
    "        'TMIN_13',\n",
    "        'TMIN_14',\n",
    "        'TMIN_15',\n",
    "        'TMIN_16',\n",
    "        'TMIN_17',\n",
    "        'TMIN_18',\n",
    "        'TMIN_19',\n",
    "        'TMIN_20',\n",
    "    ]\n",
    "\n",
    "    # ------\n",
    "    # EITHER   \n",
    "    # ------\n",
    "      # df_test = load_submission_file()\n",
    "      # # fill in the missing days\n",
    "      # print('* Generating complete test frame \\t\\t\\t', end='')\n",
    "      # df_test = generate_complete_test_frame(df_test)\n",
    "    # ------\n",
    "    # OR\n",
    "    # ------\n",
    "    print('* Loading complete test frame... ')\n",
    "    df_test = load_compltete_test_frame()\n",
    "    \n",
    "    print('* Enriching test frame (date, coordinates) ...')\n",
    "    df_test = prepare_submission_file(df_test)\n",
    "    df_test = df_test.sort_values(by=['ID', 'DATE'])\n",
    "\n",
    "    # iteratively create predictions\n",
    "    df_prediction = pd.DataFrame(columns=['SUB_ID', 'DATA_VALUE'])\n",
    "    \n",
    "    print('* Generating Lookup Table ...')\n",
    "    df_lookup = generate_initial_lookup_of_last_20_days()\n",
    "\n",
    "    print('* Iteratively generating predictions ...')\n",
    "    stations = df_test['ID'].unique()\n",
    "    for s, station in enumerate(stations):\n",
    "        print(' '*30, '\\r', '(' + str(s+1) + '/' + str(len(stations)) + ') ::', station, '\\r', end='')\n",
    "        df_filtered_lookup = df_lookup[df_lookup['station'] == station]\n",
    "        df_filtered_test = df_test[df_test['ID'] == station]\n",
    "\n",
    "        for i,row in df_filtered_test.iterrows():\n",
    "            # get the last 20 days indeces\n",
    "            last_20_days_indices = get_last_20_day_indeces(row['day_of_year'])\n",
    "\n",
    "            features = [\n",
    "                row['day_of_year'],\n",
    "                row['lat'],\n",
    "                row['long'],\n",
    "                row['elev'],\n",
    "            ]\n",
    "            \n",
    "            # lookup the last 20 days and write them into prediction frame\n",
    "            for (j, day_index) in enumerate(last_20_days_indices):\n",
    "                features.append(int(get_value_from_lookup(df_filtered_lookup, day_index)))\n",
    "                \n",
    "            # predict temperature for that day\n",
    "            prediction = model.predict([features])\n",
    "            \n",
    "            # write prediction into lookup frame\n",
    "            df_filtered_lookup = df_filtered_lookup.append(pd.DataFrame([[station, row['DATE'], row['day_of_year'], prediction[0]]], columns=['station', 'date', 'day_of_year', 'TMIN']))\n",
    "            \n",
    "            # write prediction into solution frame\n",
    "            df_prediction = df_prediction.append(pd.DataFrame([[str(row['DATE']) + station, prediction[0]]], columns=['SUB_ID', 'DATA_VALUE']))\n",
    "\n",
    "\n",
    "    print('')    \n",
    "    \n",
    "    print('* Saving full prediction set ...')\n",
    "    df_prediction.to_csv('../data/predictions/2018_20_days_predictions_complete.csv', index=False)\n",
    "    df_prediction = df_prediction.set_index('SUB_ID')\n",
    "    \n",
    "    print('* Generating submission file ...')\n",
    "    df_submission = load_submission_file()\n",
    "    \n",
    "    predictions = []\n",
    "    for i, row in df_submission.iterrows():\n",
    "        SUB_ID = str(row['DATE']) + row['ID']\n",
    "        if SUB_ID in df_prediction.index:\n",
    "#             print('\\t', 'SUCCESS :: <' + SUB_ID + '>  in index')\n",
    "            predictions.append([SUB_ID, df_prediction.loc[SUB_ID]['DATA_VALUE']])\n",
    "        else:\n",
    "            print('\\t', 'Error :: <' + SUB_ID + '> not in index')\n",
    "        \n",
    "    df_final_predictions = pd.DataFrame(predictions, columns=['SUB_ID', 'DATA_VALUE'])\n",
    "    df_final_predictions.to_csv('../data/predictions/2018_20_days_submission_.csv', index=False)\n",
    "    \n",
    "    print('DONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading complete test frame... \n",
      "* Enriching test frame (date, coordinates) ...\n",
      "* Generating Lookup Table ...\n",
      "* Iteratively generating predictions ...\n",
      " (11874/11874) :: ZI000067983  \n",
      "* Saving full prediction set ...\n",
      "* Generating submission file ...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "generate_predictions_from_20_days_random_forest_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_from_5_days_random_forest_model():\n",
    "    model = load_model('../models/mike/5_days_random_forest.pkl')\n",
    "    TRAIN_COLUMNS = [\n",
    "        'day_of_year',\n",
    "        'lat',\n",
    "        'long',\n",
    "        'elev',\n",
    "        'TMIN_1',\n",
    "        'TMIN_2',\n",
    "        'TMIN_3',\n",
    "        'TMIN_4',\n",
    "        'TMIN_5',\n",
    "    ]\n",
    "\n",
    "    # ------\n",
    "    # EITHER   \n",
    "    # ------\n",
    "      # df_test = load_submission_file()\n",
    "      # # fill in the missing days\n",
    "      # print('* Generating complete test frame \\t\\t\\t', end='')\n",
    "      # df_test = generate_complete_test_frame(df_test)\n",
    "    # ------\n",
    "    # OR\n",
    "    # ------\n",
    "    print('* Loading complete test frame... ')\n",
    "    df_test = load_compltete_test_frame()\n",
    "    \n",
    "    print('* Enriching test frame (date, coordinates) ...')\n",
    "    df_test = prepare_submission_file(df_test)\n",
    "    df_test = df_test.sort_values(by=['ID', 'DATE'])\n",
    "\n",
    "    # iteratively create predictions\n",
    "    df_prediction = pd.DataFrame(columns=['SUB_ID', 'DATA_VALUE'])\n",
    "    \n",
    "    print('* Generating Lookup Table ...')\n",
    "    df_lookup = generate_initial_lookup_of_last_20_days()\n",
    "\n",
    "    print('* Iteratively generating predictions ...')\n",
    "    stations = df_test['ID'].unique()\n",
    "    for s, station in enumerate(stations):\n",
    "        print(' '*30, '\\r', '(' + str(s+1) + '/' + str(len(stations)) + ') ::', station, '\\r', end='')\n",
    "        df_filtered_lookup = df_lookup[df_lookup['station'] == station]\n",
    "        df_filtered_test = df_test[df_test['ID'] == station]\n",
    "\n",
    "        for i,row in df_filtered_test.iterrows():\n",
    "            # get the last 20 days indeces\n",
    "            last_5_days_indices = get_last_5_day_indeces(row['day_of_year'])\n",
    "\n",
    "            features = [\n",
    "                row['day_of_year'],\n",
    "                row['lat'],\n",
    "                row['long'],\n",
    "                row['elev'],\n",
    "            ]\n",
    "            \n",
    "            # lookup the last 5 days and write them into prediction frame\n",
    "            for (j, day_index) in enumerate(last_5_days_indices):\n",
    "                features.append(int(get_value_from_lookup(df_filtered_lookup, day_index)))\n",
    "                \n",
    "            # predict temperature for that day\n",
    "            prediction = model.predict([features])\n",
    "            \n",
    "            # write prediction into lookup frame\n",
    "            df_filtered_lookup = df_filtered_lookup.append(pd.DataFrame([[station, row['DATE'], row['day_of_year'], prediction[0]]], columns=['station', 'date', 'day_of_year', 'TMIN']))\n",
    "            \n",
    "            # write prediction into solution frame\n",
    "            df_prediction = df_prediction.append(pd.DataFrame([[str(row['DATE']) + station, prediction[0]]], columns=['SUB_ID', 'DATA_VALUE']))\n",
    "\n",
    "\n",
    "    print('')    \n",
    "    \n",
    "    print('* Saving full prediction set ...')\n",
    "    df_prediction.to_csv('../data/predictions/2018_5_days_predictions_complete.csv', index=False)\n",
    "    df_prediction = df_prediction.set_index('SUB_ID')\n",
    "    \n",
    "    print('* Generating submission file ...')\n",
    "    df_submission = load_submission_file()\n",
    "    \n",
    "    predictions = []\n",
    "    for i, row in df_submission.iterrows():\n",
    "        SUB_ID = str(row['DATE']) + row['ID']\n",
    "        if SUB_ID in df_prediction.index:\n",
    "#             print('\\t', 'SUCCESS :: <' + SUB_ID + '>  in index')\n",
    "            predictions.append([SUB_ID, df_prediction.loc[SUB_ID]['DATA_VALUE']])\n",
    "        else:\n",
    "            print('\\t', 'Error :: <' + SUB_ID + '> not in index')\n",
    "        \n",
    "    df_final_predictions = pd.DataFrame(predictions, columns=['SUB_ID', 'DATA_VALUE'])\n",
    "    df_final_predictions.to_csv('../data/predictions/2018_5_days_submission_.csv', index=False)\n",
    "    \n",
    "    print('DONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading complete test frame... \n",
      "* Enriching test frame (date, coordinates) ...\n",
      "* Generating Lookup Table ...\n",
      "* Iteratively generating predictions ...\n",
      " (11874/11874) :: ZI000067983  \n",
      "* Saving full prediction set ...\n",
      "* Generating submission file ...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "generate_predictions_from_5_days_random_forest_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

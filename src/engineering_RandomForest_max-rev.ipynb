{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #to supress import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data ready for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the preprocessed data for a quicker start\n",
    "\n",
    "TRAIN_FILE = '../data/tmp/export_LSMT_MAX_yd.csv'\n",
    "STATIONS_FILE = '../data/ghcnd-stations.csv'\n",
    "\n",
    "def get_original_df():\n",
    "    df_original = pd.read_csv(TRAIN_FILE)\n",
    "    df_original = df_original.drop(['Unnamed: 0'], axis=1)\n",
    "    return df_original\n",
    "\n",
    "def get_station_df():\n",
    "     return pd.read_csv(STATIONS_FILE, header=None, names=['station','lat', 'long', 'elev'], sep=';')\n",
    "\n",
    "def add_coordinates(df_src, df_stations, src_index='station', foreign_index='station'):\n",
    "    df_out = df_src.copy()\n",
    "    return df_out.join(df_stations.set_index(foreign_index), on=src_index)\n",
    "\n",
    "def add_cluster_ids(df_src, cluster_file_paths = []):\n",
    "    df_out = df_src.copy()\n",
    "    for path in cluster_file_paths:\n",
    "        df_cluster = pd.read_csv(path)\n",
    "        df_out = df_out.join(df_cluster.set_index('station'), on='ID', how='left')\n",
    "    return df_out\n",
    "\n",
    "def add_day_of_year_column(df_src, column_name='date'):\n",
    "    df_out = df_src.copy()\n",
    "    df_out['day'] = df_out[column_name].apply(lambda d: date_to_nth_day(str(d)))\n",
    "    return df_out\n",
    "\n",
    "def date_to_nth_day(date, format='%Y%m%d'):\n",
    "    try:\n",
    "        date = datetime.strptime(date, format)\n",
    "        new_year_day = datetime(year=date.year, month=1, day=1)\n",
    "    except:\n",
    "        print(date)\n",
    "    return (date - new_year_day).days + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>elev</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>128</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>145</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>140</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>162</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>115</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station  TMIN     lat    long  elev  year  day\n",
       "0  AE000041196   128  25.333  55.517  34.0  2014    1\n",
       "1  AE000041196   145  25.333  55.517  34.0  2014    2\n",
       "2  AE000041196   140  25.333  55.517  34.0  2014    3\n",
       "3  AE000041196   162  25.333  55.517  34.0  2014    6\n",
       "4  AE000041196   115  25.333  55.517  34.0  2014    9"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/tmp/export_LSMT_MAX_yd.csv', index_col=0, low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id_2</th>\n",
       "      <th>cluster_id_4</th>\n",
       "      <th>cluster_id_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AE000041196</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEM00041194</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEM00041217</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEM00041218</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AG000060390</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cluster_id_2  cluster_id_4  cluster_id_6\n",
       "station                                              \n",
       "AE000041196             0             3             4\n",
       "AEM00041194             0             3             4\n",
       "AEM00041217             0             3             4\n",
       "AEM00041218             0             3             4\n",
       "AG000060390             0             1             1"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster = pd.read_csv('../data/cluster/station_clustertemperature.csv', index_col=0, low_memory=False)\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_cluster, on='station', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>elev</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>cluster_id_2</th>\n",
       "      <th>cluster_id_4</th>\n",
       "      <th>cluster_id_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>128</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>145</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>140</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>162</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>115</td>\n",
       "      <td>25.333</td>\n",
       "      <td>55.517</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station  TMIN     lat    long  elev  year  day  cluster_id_2  \\\n",
       "0  AE000041196   128  25.333  55.517  34.0  2014    1             0   \n",
       "1  AE000041196   145  25.333  55.517  34.0  2014    2             0   \n",
       "2  AE000041196   140  25.333  55.517  34.0  2014    3             0   \n",
       "3  AE000041196   162  25.333  55.517  34.0  2014    6             0   \n",
       "4  AE000041196   115  25.333  55.517  34.0  2014    9             0   \n",
       "\n",
       "   cluster_id_4  cluster_id_6  \n",
       "0             3             4  \n",
       "1             3             4  \n",
       "2             3             4  \n",
       "3             3             4  \n",
       "4             3             4  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick random stations for test and training\n",
    "seed = 93598357\n",
    "np.random.seed(seed)\n",
    "stations = df.station.unique()\n",
    "np.random.shuffle(stations)\n",
    "stations_shuffled = stations\n",
    "fraction = 4\n",
    "stations_train = stations_shuffled[:int(np.round(len(stations)/fraction))]\n",
    "stations_holdout14 = stations_shuffled[int(np.round(len(stations)/fraction)):int(np.round(len(stations)/fraction*2))]\n",
    "stations_holdout15 = stations_shuffled[int(np.round(len(stations)/fraction*2)):int(np.round(len(stations)/fraction*3))]\n",
    "stations_holdout16 = stations_shuffled[int(np.round(len(stations)/fraction*3)):int(np.round(len(stations)/fraction*4))]\n",
    "\n",
    "df_17 = df#[df['station'].isin(stations_train)]\n",
    "df_14 = df#[df['station'].isin(stations_holdout14)]\n",
    "df_15 = df#[df['station'].isin(stations_holdout15)]\n",
    "df_16 = df#[df['station'].isin(stations_holdout16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18683824 18683824 18683824 18683824\n"
     ]
    }
   ],
   "source": [
    "print(len(df_17), len(df_14), len(df_15), len(df_16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4591256, 10)\n"
     ]
    }
   ],
   "source": [
    "#divide test and training to test effective of model to different timeframe (start of 2017)\n",
    "testing_days = list(range(52))\n",
    "\n",
    "df_train = df[df['day'].isin(testing_days)]\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1952163, 10) (621748, 10)\n",
      "(1914389, 10) (659522, 10)\n",
      "(1921719, 10) (652192, 10)\n",
      "(1933462, 10) (640449, 10)\n"
     ]
    }
   ],
   "source": [
    "#divide test and training to test effective of model to different timeframe (start of 2017)\n",
    "training_years = [2014,2015,2016]\n",
    "testing_days = list(range(51))\n",
    "\n",
    "df_train17 = df_17[df_17['year'].isin(training_years)]\n",
    "df_train17 = df_train17[df_train17['day'].isin(testing_days)]\n",
    "df_test17 = df_17[~df_17['year'].isin(training_years)]\n",
    "df_test17 = df_test17[df_test17['day'].isin(testing_days)]\n",
    "print(df_train17.shape,df_test17.shape)\n",
    "\n",
    "training_years = [2017,2015,2016]\n",
    "df_train14 = df_14[df_14['year'].isin(training_years)]\n",
    "df_train14 = df_train14[df_train14['day'].isin(testing_days)]\n",
    "df_test14 = df_14[~df_14['year'].isin(training_years)]\n",
    "df_test14 = df_test14[df_test14['day'].isin(testing_days)]\n",
    "print(df_train14.shape,df_test14.shape)\n",
    "\n",
    "training_years = [2017,2014,2016]\n",
    "df_train15 = df_15[df_15['year'].isin(training_years)]\n",
    "df_train15 = df_train15[df_train15['day'].isin(testing_days)]\n",
    "df_test15 = df_15[~df_15['year'].isin(training_years)]\n",
    "df_test15 = df_test15[df_test15['day'].isin(testing_days)]\n",
    "print(df_train15.shape,df_test15.shape)\n",
    "\n",
    "training_years = [2017,2015,2014]\n",
    "df_train16 = df_16[df_16['year'].isin(training_years)]\n",
    "df_train16 = df_train16[df_train16['day'].isin(testing_days)]\n",
    "df_test16 = df_16[~df_16['year'].isin(training_years)]\n",
    "df_test16 = df_test16[df_test16['day'].isin(testing_days)]\n",
    "print(df_train16.shape,df_test16.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define split for CV later on\n",
    "split = [[df_train17.index.values, df_test17.index.values], [df_train16.index.values, df_test16.index.values],\n",
    "         [df_train15.index.values, df_test15.index.values],[df_train14.index.values, df_test14.index.values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate target from features\n",
    "df_X_raw = df_train.drop(columns=['TMIN', 'elev', 'lat', 'long'])\n",
    "df_X_raw_cv = df.drop(columns=['TMIN', 'elev', 'lat', 'long'])\n",
    "sy = df_train['TMIN']\n",
    "sy_cv = df['TMIN']\n",
    "y_raw = sy.reshape(-1,1)\n",
    "y_raw_cv = sy_cv.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4591256, 6)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int encode stations\n",
    "#LB = LabelBinarizer()\n",
    "#df_X['station'] = LB.fit_transform(df_X[['station']])\n",
    "df_X_red = df_X_raw.drop(columns='station')\n",
    "df_X_red_cv = df_X_raw_cv.drop(columns='station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_dict = df_X.to_dict('records')\n",
    "#vec = DictVectorizer()\n",
    "#X = vec.fit_transform(X_dict).toarray()\n",
    "#X_dummies = pd.get_dummies(df_X)\n",
    "#X = X_dummies.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "X_raw = df_X_red.values\n",
    "X_raw_cv = df_X_red_cv.values\n",
    "y_raw = y_raw.astype('float32')\n",
    "y_raw_cv = y_raw_cv.astype('float32')\n",
    "\n",
    "X = X_raw\n",
    "X_cv = X_raw_cv\n",
    "y = y_raw.ravel()\n",
    "y_cv = y_raw_cv.ravel()\n",
    "\n",
    "\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))                             \n",
    "#X = scaler.fit_transform(X_raw)\n",
    "#X_cv = scaler.fit_transform(X_raw_cv)\n",
    "#y = scaler.fit_transform(y_raw).ravel()\n",
    "#y_cv = scaler.fit_transform(y_raw_cv).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 10,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 3, 'max_depth': 10, 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/maximilianwuhr/Documents/WebDev/DataMining/.dma/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/maximilianwuhr/Documents/WebDev/DataMining/.dma/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/maximilianwuhr/Documents/WebDev/DataMining/.dma/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/maximilianwuhr/Documents/WebDev/DataMining/.dma/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-b879c4bab1af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/WebDev/DataMining/.dma/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/WebDev/DataMining/.dma/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/WebDev/DataMining/.dma/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [50, 100, 150],\n",
    "    \"max_depth\":[7, 10, 13],\n",
    "    \"max_features\": [2, 3, 4],\n",
    "    \"min_samples_split\": [10],\n",
    "    \"min_samples_leaf\": [10, 15],\n",
    "    \"bootstrap\": [True]}\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "grid = RandomizedSearchCV(estimator=model, verbose=2, param_distributions=param_grid, n_iter=25, cv=split, n_jobs=-1)\n",
    "grid.fit(X_cv, y_cv)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features=3, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=10,\n",
       "           min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
       "           verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = RandomForestRegressor(n_estimators=100, min_samples_split=10, min_samples_leaf=10, max_features=3, max_depth= 10, bootstrap=True, random_state=0, verbose=2)\n",
    "#grid = RandomizedSearchCV(estimator=model, verbose=2, param_distributions=param_grid, n_iter=25, cv=split, n_jobs=-1)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       12307.3693            5.06m\n",
      "         2       10356.7172            5.41m\n",
      "         3        9054.7328            5.58m\n",
      "         4        7977.4248            5.31m\n",
      "         5        7202.6330            5.19m\n",
      "         6        6637.6004            5.05m\n",
      "         7        6201.0322            4.95m\n",
      "         8        5892.4709            4.82m\n",
      "         9        5666.6661            4.78m\n",
      "        10        5503.2164            4.78m\n",
      "        11        5368.4790            4.74m\n",
      "        12        5276.6127            4.64m\n",
      "        13        5207.5102            4.54m\n",
      "        14        5155.0206            4.50m\n",
      "        15        5108.7731            4.65m\n",
      "        16        5077.0640            4.66m\n",
      "        17        5048.4421            4.57m\n",
      "        18        5032.3667            4.56m\n",
      "        19        5014.2602            4.53m\n",
      "        20        4997.5841            4.47m\n",
      "        21        4989.0457            4.40m\n",
      "        22        4976.4106            4.36m\n",
      "        23        4968.9805            4.31m\n",
      "        24        4964.3511            4.24m\n",
      "        25        4960.3529            4.22m\n",
      "        26        4952.1737            4.19m\n",
      "        27        4941.5980            4.19m\n",
      "        28        4933.7213            4.18m\n",
      "        29        4925.1162            4.15m\n",
      "        30        4922.9364            4.12m\n",
      "        31        4917.5574            4.12m\n",
      "        32        4906.3326            4.16m\n",
      "        33        4901.3953            4.12m\n",
      "        34        4900.1535            4.02m\n",
      "        35        4893.2468            3.99m\n",
      "        36        4889.9146            3.95m\n",
      "        37        4882.5334            3.91m\n",
      "        38        4881.4436            3.88m\n",
      "        39        4878.6856            3.82m\n",
      "        40        4870.5742            3.78m\n",
      "        41        4869.7942            3.70m\n",
      "        42        4866.2786            3.63m\n",
      "        43        4859.7127            3.59m\n",
      "        44        4851.0069            3.55m\n",
      "        45        4849.0306            3.48m\n",
      "        46        4844.3678            3.41m\n",
      "        47        4839.3812            3.34m\n",
      "        48        4836.2304            3.27m\n",
      "        49        4834.2887            3.21m\n",
      "        50        4832.1165            3.17m\n",
      "        51        4831.3558            3.12m\n",
      "        52        4829.1078            3.05m\n",
      "        53        4826.7738            3.01m\n",
      "        54        4825.0516            2.96m\n",
      "        55        4822.1008            2.90m\n",
      "        56        4817.8237            2.84m\n",
      "        57        4817.3838            2.76m\n",
      "        58        4815.8940            2.70m\n",
      "        59        4814.1494            2.63m\n",
      "        60        4813.9098            2.56m\n",
      "        61        4811.1017            2.49m\n",
      "        62        4804.9142            2.42m\n",
      "        63        4803.9761            2.36m\n",
      "        64        4802.0815            2.30m\n",
      "        65        4800.6380            2.24m\n",
      "        66        4798.7100            2.19m\n",
      "        67        4794.4617            2.12m\n",
      "        68        4791.3718            2.06m\n",
      "        69        4788.3082            1.99m\n",
      "        70        4787.2745            1.94m\n",
      "        71        4785.3230            1.87m\n",
      "        72        4783.2823            1.81m\n",
      "        73        4782.4729            1.74m\n",
      "        74        4781.5001            1.68m\n",
      "        75        4778.9787            1.62m\n",
      "        76        4777.7373            1.55m\n",
      "        77        4777.2678            1.48m\n",
      "        78        4774.9980            1.42m\n",
      "        79        4773.3398            1.36m\n",
      "        80        4771.3075            1.29m\n",
      "        81        4770.3678            1.23m\n",
      "        82        4768.2774            1.16m\n",
      "        83        4767.5869            1.10m\n",
      "        84        4766.1877            1.04m\n",
      "        85        4763.8883           58.66s\n",
      "        86        4763.4858           55.07s\n",
      "        87        4763.1783           51.33s\n",
      "        88        4762.9626           47.39s\n",
      "        89        4762.9089           43.35s\n",
      "        90        4761.6508           39.52s\n",
      "        91        4760.6799           35.68s\n",
      "        92        4760.1844           31.67s\n",
      "        93        4759.8576           27.70s\n",
      "        94        4758.5225           23.73s\n",
      "        95        4756.2615           19.77s\n",
      "        96        4754.8348           15.80s\n",
      "        97        4754.4246           11.84s\n",
      "        98        4753.9535            7.86s\n",
      "        99        4753.6208            3.93s\n",
      "       100        4752.7982            0.00s\n",
      "0.6834216060141713\n"
     ]
    }
   ],
   "source": [
    "boost = GradientBoostingRegressor(n_estimators= 100, learning_rate=0.15, max_depth=5, max_features=3, min_samples_split=100, \n",
    "                                  min_samples_leaf=100, random_state=0, verbose=2)\n",
    "boost.fit(X, y)\n",
    "\n",
    "print(boost.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/max/boosting_clustered.pkl']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(boost, '../models/max/boosting_clustered.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/max/simple_random_forest_clustered.pkl']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, '../models/max/simple_random_forest_clustered.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_PATH = '../data/2018_test_org.csv'\n",
    "def load_submission_file():\n",
    "    df_test = pd.read_csv(SUBMISSION_PATH)\n",
    "    return df_test\n",
    "\n",
    "def prepare_submission_file(df_test):\n",
    "    df_stations = get_station_df()\n",
    "    print('\\t * Add coordinates')\n",
    "    df_out = add_coordinates(df_test, df_stations, src_index='ID', foreign_index='station')\n",
    "    print('\\t * Add day of year')\n",
    "    df_out = add_day_of_year_column(df_out, column_name='DATE')\n",
    "    print('\\t * Add cluster ids')\n",
    "    df_out = add_cluster_ids(df_out, cluster_file_paths = [\n",
    "        '../data/cluster/station_clustertemperature.csv'\n",
    "    ])\n",
    "    return df_out\n",
    "    \n",
    "def save_submission(df_src, PATH):\n",
    "    df_submission = pd.DataFrame()\n",
    "    df_submission['SUB_ID'] = df_src['DATE'].apply(lambda d: str(d)) + df_src['ID']\n",
    "    df_submission['DATA_VALUE'] = df_src['DATA_VALUE']\n",
    "    df_submission.to_csv(PATH, index=False)\n",
    "    return df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_from_clustered_random_forest_model():\n",
    "    model = joblib.load('../models/max/simple_random_forest_clustered.pkl')\n",
    "    required_features = [\n",
    "        'day',\n",
    "        'year',\n",
    "        'cluster_id_2',\n",
    "        'cluster_id_4',\n",
    "        'cluster_id_6'\n",
    "        ]\n",
    "    PREDICITON_FILE_PATH = '../data/predictions/prediction_simple_random_forest_clustered_MAX.csv'\n",
    "    \n",
    "    print('* Load submission file')\n",
    "    df_test = load_submission_file()\n",
    "    print('* Prepare submission file')\n",
    "    df_test = prepare_submission_file(df_test)\n",
    "    print('* Add year column')\n",
    "    df_test['year'] = 2018\n",
    "#    df_test = df_test.dropna(axis=0, how='all')\n",
    "\n",
    "    # create predictions\n",
    "    df_predict = df_test\n",
    "    df_predict['DATA_VALUE'] = model.predict(df_test[required_features])\n",
    "\n",
    "    #save predictions\n",
    "    df_submission = save_submission(df_predict, PREDICITON_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_from_clustered_boosting_model():\n",
    "    model = joblib.load('../models/max/boosting_clustered.pkl')\n",
    "    required_features = [\n",
    "        'day',\n",
    "        'year',\n",
    "        'cluster_id_2',\n",
    "        'cluster_id_4',\n",
    "        'cluster_id_6'\n",
    "        ]\n",
    "    PREDICITON_FILE_PATH = '../data/predictions/prediction_boosting_clustered_MAX.csv'\n",
    "    \n",
    "    print('* Load submission file')\n",
    "    df_test = load_submission_file()\n",
    "    print('* Prepare submission file')\n",
    "    df_test = prepare_submission_file(df_test)\n",
    "    print('* Add year column')\n",
    "    df_test['year'] = 2018\n",
    "#    df_test = df_test.dropna(axis=0, how='all')\n",
    "\n",
    "    # create predictions\n",
    "    df_predict = df_test\n",
    "    df_predict['DATA_VALUE'] = model.predict(df_test[required_features])\n",
    "\n",
    "    #save predictions\n",
    "    df_submission = save_submission(df_predict, PREDICITON_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Load submission file\n",
      "* Prepare submission file\n",
      "\t * Add coordinates\n",
      "\t * Add day of year\n",
      "\t * Add cluster ids\n",
      "* Add year column\n"
     ]
    }
   ],
   "source": [
    "generate_predictions_from_clustered_boosting_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Load submission file\n",
      "* Prepare submission file\n",
      "\t * Add coordinates\n",
      "\t * Add day of year\n",
      "\t * Add cluster ids\n",
      "* Add year column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "generate_predictions_from_clustered_random_forest_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
